---
title: "analysis"
format: html
editor: visual
---

## Load Data & Create Factors

```{r, echo= FALSE, warning = FALSE}
library("dplyr")
library(mice)
library(sjlabelled)
library(tidyverse)


combined <- read.csv('https://github.com/wujenny214/F24_STATS_FINAL/raw/refs/heads/main/combined.csv')
```

```{r}
head(combined)
```

```{r}
combined <- combined |> mutate(State_fac = factor(combined$State), Region_fac = factor(combined$Region, levels=c('South', 'West', 'Northeast', 'Midwest')))
```

```{r}
combined <- combined %>% select(-X, -Spending.per.Pupil)
```

```{r}
head(combined)
```

## Imputation

```{r}
sub <- combined |> select(c("Life.Expectancy","Residential.Segregation.Index","X..Limited.Access.to.Healthy.Foods","X..Uninsured.Adults","Median.Household.Income", "School.Funding.Adequacy", "Median.Prop.Tax", "Region_fac"))
sub <- unlabel(sub) #unlabel the data (labels cause problem for the mice function)
sub.imp <- mice(sub, m=5, method="pmm", print=FALSE)
```

```{r}
#Need to convert school funding adequacy imputed values to school funding categorical variable before using in models
# Imputated data has 5 dataframes within a list, need to run a loop for all five datasets to create a categorical variable for each set. 

sub <- combined |> select(c("Life.Expectancy","Residential.Segregation.Index","X..Limited.Access.to.Healthy.Foods","X..Uninsured.Adults","Median.Household.Income", "School.Funding.Adequacy", "Median.Prop.Tax", "Region_fac"))
sub <- unlabel(sub) #unlabel the data (labels cause problem for the mice function)


# Perform the imputation
sub$School.Funding.Cat <- ifelse(sub$School.Funding.Adequacy > 0, 1, 0)  # Add the new variable to the dataset
sub.imp <- mice(sub, m = 5, method = "pmm", print = FALSE)

```

```{r}
# To create a School.Funding.Categorical variable, create a function and run the loop

# Define the categorization function
categorize_school_funding <- function(x) {
  ifelse(x > 0, 1, 0)  # Binary classification
}

# Loop over the imputations
for (i in 1:5) {
  # Extract the imputed values for the i-th dataset
  imputed_values <- sub.imp$imp$School.Funding.Adequacy[, i]
  
  # Categorize the imputed values
  categorized_values <- categorize_school_funding(imputed_values)
  complete_cat <- rep(NA, nrow(sub))  # Initialize with NAs
  
  # Get the indices where imputation occurred
  imp_indices <- which(!is.na(categorized_values))  # Only for imputed values

  # Assign the categorized values to the rows that were imputed
  complete_cat[imp_indices] <- categorized_values[imp_indices]
  
  # Save into the `imp` list of the `sub.imp` object
  sub.imp$imp$School.Funding.Cat[[i]] <- complete_cat[imp_indices]
}
```

```{r}
long_data <- complete(sub.imp, action = "long", include = TRUE)  # Include original data


# Check the structure
str(long_data)

# Ensure that `School.Funding.Cat` is correctly populated
long_data$School.Funding.Cat <- ifelse(long_data$School.Funding.Adequacy > 0, 1, 0)


if (!".imp" %in% colnames(long_data) || !".id" %in% colnames(long_data)) {
  stop("`.imp` or `.id` columns are missing in the long data!")
}
```

## Q1

```{r}
#MLR
# Outcome = life expectancy #Predictors = residential segregation, limited access to healthy foods, uninsured adults, region_fac as interaction with residential segregation (or any other variable)

mlrmodel <- lm(
  Life.Expectancy ~ Residential.Segregation.Index +
    X..Limited.Access.to.Healthy.Foods +
    X..Uninsured.Adults,
  data = combined)
summary(mlrmodel)

```

```{r}
mlr.imp.mod <- with(sub.imp, lm(Life.Expectancy ~ Residential.Segregation.Index +
    X..Limited.Access.to.Healthy.Foods +
    X..Uninsured.Adults + 
    Region_fac))

summary(pool(mlr.imp.mod))
```

```{r}
mlr.imp.mod2 <- with(sub.imp, lm(Life.Expectancy ~ Residential.Segregation.Index +
    X..Limited.Access.to.Healthy.Foods +
    X..Uninsured.Adults + 
    Region_fac + 
    Region_fac * Residential.Segregation.Index))

summary(pool(mlr.imp.mod2))
```

\@ UZO: Add plots to check assumptions: QQ plot, nested F-test, write p-value interpretations, VIF, Cooks distance

```{r}
#QQPlot
qqnorm(residuals(mlrmodel))
qqline(residuals(mlrmodel), col = "red") 
```

```{r}
##Nested F-Test
#Assuming we will drop %Uninsured Adults Predictor

#print(colnames(combined))
reduced_model <- lm(Life.Expectancy ~ Residential.Segregation.Index + X..Limited.Access.to.Healthy.Foods, data = combined) 
  
# Nested F-Test
anova(reduced_model, mlrmodel)
```

```{r}
#Cooks Distance 
cooksd <- cooks.distance(mlrmodel)

# Plot Cook's Distance
plot(cooksd, main = "Cook's Distance", ylab = "Cook's Distance")
abline(h = 4/(nrow(data) - length(coef(mlrmodel))), col = "red")  # Threshold line

# Identify Influential Points
influential <- which(cooksd > 4/(nrow(combined) - length(coef(mlrmodel))))
print(influential)
```

```{r}
#Variance Inflaction Factor (VIF)
library(car)
vif(mlrmodel)
```

Results are all slightly greater than one meaning some correlation between factors but not much. Percentage of uninsured adults having the greatest correlation

```{r}
#Generate 4 Diagnostic Plots at once
par(mfrow = c(2, 2), mar = c(4,4,2,2))
plot(mlrmodel)
```

## Q2

```{r}
## Checking to see if the imputated data has a large effect on the outcome 

# Logistic Regression without Imputated Data
# Outcome = School.Funding.Cat
# Predictors = residential segregation, median.household.income, median.prop.tax

lmod <- glm(School.Funding.Cat ~ Residential.Segregation.Index + Median.Household.Income + Median.Prop.Tax,
              data=combined,
              family="binomial")

library("modelsummary")
modelsummary(lmod,
             fmt = fmt_significant(2),
             shape = term ~ model + statistic,
             statistic = c("std.error","conf.int","p.value"),
             exponentiate = FALSE,
             gof_map=NA)

modelsummary(lmod,
             fmt = fmt_significant(2),
             shape = term ~ model + statistic,
             statistic = c("std.error","conf.int","p.value"),
             exponentiate = TRUE,
             gof_map=NA)

```

```{r}
imp_mods <- with(sub_imp, glm(School.Funding.Cat ~ Residential.Segregation.Index + Median.Household.Income + Median.Prop.Tax), family="binomial")

modelsummary(pool(imp_mods),
             fmt = fmt_significant(2),
             shape = term ~ model + statistic,
             statistic = c("std.error","conf.int","p.value"),
             exponentiate = FALSE,
             gof_map=NA)

modelsummary(pool(imp_mods),
             fmt = fmt_significant(2),
             shape = term ~ model + statistic,
             statistic = c("std.error","conf.int","p.value"),
             exponentiate = TRUE,
             gof_map=NA)
```

```{r}
# Creating the AUC curve

library(caret)
library(pROC)

set.seed(42)
train_idx <- sample(1:nrow(long_data), size = 0.7 * nrow(long_data))
train_data <- long_data[train_idx, ]
test_data <- long_data[-train_idx, ]

glm_model <- glm(School.Funding.Cat ~ Residential.Segregation.Index + Median.Household.Income + Median.Prop.Tax, data = train_data, family = binomial)

# Step 4: Make predictions on the test set
test_probs <- predict(glm_model, newdata = test_data, type = "response")
test_pred <- ifelse(test_probs > 0.5, 1, 0)  # Classify based on threshold 0.5

# Step 5: Create a confusion matrix
conf_matrix <- confusionMatrix(factor(test_pred), factor(test_data$School.Funding.Cat))
print(conf_matrix)
```

